defaults:
  - _self_
  - rewards:
    - action_penalty
    - object_pos_err

name: claw_env

config:
  _target_: dmanip.envs.ClawWarpEnv
  num_envs: 128
  episode_length: 500
  render: ${general.render}
  no_grad: ???
  # rew_params: 
  #   action_penalty: ${...rewards.action_penalty}
  #   object_pos_err: ${...rewards.object_pos_err}
  #   object_joint_pos_err: ${...rewards.object_joint_pos_err}
  stochastic_init: true
  seed: ${general.seed}
  action_type: ${action:position}
  object_type: ${object:octprism}
  goal_type: ${goal:orientation}
  reward_type: ${reward:delta}

shac:
  actor_lr: 1e-3
  critic_lr: 1e-2
  actor: ActorStochasticMLP # ActorDeterministicMLP
  actor_mlp:
    units: [128, 64, 32]
    activation: elu

  critic: CriticMLP
  critic_mlp:
    units: [64, 64]
    activation: elu


ppo:
  max_epochs: 500
  minibatch_size: 1920
  save_interval: 100
  save_best_after: 50
  num_actors: 32
  steps_num: 240

player:
  deterministic: True
  games_num: 12
  num_actors: 4
  print_stats: True
